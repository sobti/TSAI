{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EVA P2S3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sobti/TSAI/blob/master/LSTM/EVA_P2S3_50000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U",
        "outputId": "cdd0f66a-0f04-4c46-b47f-8cc42b3cea18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "drive.mount('/content/gdrive/')\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "outputId": "e8d49698-79bf-46a7-9180-5db295c21a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return (1/(1 + np.exp(-y))) * (1-1/(1 + np.exp(-y)))\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)) \n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1-y**2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDGwbQvLyAzQ",
        "outputId": "b2c69296-27cf-4580-deb9-2900f0f4b0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vQrnLbTyEPM",
        "outputId": "a0ec4b2d-93c6-4066-ac2c-348ebf95bf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2350037122015945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx98medHyvRw",
        "outputId": "8c5efd74-2cf9-4738-a78f-f9e318eb0293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2307710272926823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OttziLKby5gS",
        "outputId": "c61d7f72-ab9c-4581-b54f-bb34f91cc71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0)))) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9467447329622801"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    z = np.row_stack((h_prev, x))\n",
        "    W_f, W_i, W_C, W_o, W_v,b_f, b_i, b_C, b_o,b_v=parameters.all()\n",
        "    f = sigmoid(np.dot(W_f.v,z)+b_f.v) # write your code here\n",
        "    i = sigmoid(np.dot(W_i.v,z)+b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(W_C.v,z)+b_C.v)# write your code here\n",
        "\n",
        "    C = f * C_prev + i * C_bar     # write your code here\n",
        "    o = sigmoid(np.dot(W_o.v,z)+b_o.v) # write your code here\n",
        "    h = o * tanh(C)                  # write your code here\n",
        "\n",
        "    v = (np.dot(W_v.v,h) + b_v.v  )     # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRBCyuai919",
        "outputId": "566aad8e-f33c-4bb0-8b9d-327363062d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYs03VuXzJRm",
        "outputId": "357d6e5c-ee0a-48f9-d7b7-7f248b8aa7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "outputId": "4211cb1a-1b1e-4315-8723-b1e0e95d138d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " mi2  ioth. \n",
            " usclthtoArutozod bihata\n",
            "\n",
            "tiivet fo tnnt alem e opn aore t dsee is 8frit  ood ssatecDa a;n oinsieaMouonc.rs n n quaWtdfnonnorseN-y io\n",
            "\n",
            "1bshten auseons liid nanhern  gcoer\n",
            "\n",
            "sp'u oaor U8eeme \n",
            "----\n",
            "iter 49900, loss 112.364292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}